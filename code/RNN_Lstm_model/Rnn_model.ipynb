{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOgx-MXXdE2N",
        "outputId": "cedac67f-64fd-4eb3-cd6a-614e66266978"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.16.2\n",
            "  Downloading tensorflow-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (590.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (0.5.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (0.2.0)\n",
            "Collecting h5py>=3.10.0 (from tensorflow==2.16.2)\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.2)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (1.64.1)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.2)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras>=3.0.0 (from tensorflow==2.16.2)\n",
            "  Downloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (0.37.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (1.25.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.16.2) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.2) (13.7.1)\n",
            "Collecting namex (from keras>=3.0.0->tensorflow==2.16.2)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Collecting optree (from keras>=3.0.0->tensorflow==2.16.2)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (2024.6.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.2) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2) (0.1.2)\n",
            "Installing collected packages: namex, optree, ml-dtypes, h5py, tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.11.0 keras-3.4.1 ml-dtypes-0.3.2 namex-0.0.8 optree-0.11.0 tensorboard-2.16.2 tensorflow-2.16.2\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.16.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2D6kK6KCZwZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjsXNiQLDy-f"
      },
      "outputs": [],
      "source": [
        "\n",
        "data_text  = pd.read_csv('/content/df_commentary_new.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOwO5uyeD2fB"
      },
      "outputs": [],
      "source": [
        "def data_processing(data,number_of_rows, list_of_columns):\n",
        "    data = data.drop(columns= list_of_columns,axis=1)\n",
        "    data = data.head(number_of_rows)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecKsCFRgD5ag"
      },
      "outputs": [],
      "source": [
        "def tokenize(data):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(data['Modified_Commentary'])\n",
        "    return tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Inwgjz7lD7rx"
      },
      "outputs": [],
      "source": [
        "def input_sequences(data):\n",
        "  input_sequences = []\n",
        "  for i in range(len(data_text['Modified_Commentary'])):\n",
        "      text = data_text['Modified_Commentary'][i]\n",
        "      token_list = tokenizer.texts_to_sequences([text])[0]\n",
        "      for i in range(1, len(token_list)):\n",
        "          n_gram_sequence = token_list[:i+1]\n",
        "          input_sequences.append(n_gram_sequence)\n",
        "\n",
        "  max_len = max(len(x) for x in input_sequences)\n",
        "\n",
        "  return input_sequences, max_len\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(x) for x in input_sequences)\n",
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiLvHuO2BB0A",
        "outputId": "39333209-a801-4218-87bc-6259c6c22abf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "153"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b58F01WxD9bJ",
        "outputId": "56a2b446-d5cc-49aa-ee41-370d3875972c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x shape :  {(45086, 153)}\n",
            "x shape :  {(45086, 3583)}\n"
          ]
        }
      ],
      "source": [
        "### Calling all the functions\n",
        "\n",
        "dropped_columns = ['Unnamed: 0']\n",
        "data_text =  data_processing(data_text, 1000, dropped_columns)\n",
        "tokenizer  = tokenize(data_text)\n",
        "input_sequences, max_len = input_sequences(data_text)\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen=max_len + 1, padding='pre')\n",
        "padded_input_sequences\n",
        "x = padded_input_sequences[:, :-1]\n",
        "y = padded_input_sequences[:, -1]\n",
        "y = to_categorical(y, num_classes=len(tokenizer.word_index)+1)\n",
        "print('x shape : ',{x.shape})\n",
        "print('x shape : ',{y.shape})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snGzWDfMEBed",
        "outputId": "5f3b5223-c46f-4cf5-8c74-5ab2dd20f905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum word index: 3582\n",
            "Maximum length of a string: 798\n",
            "Index of maximum length of a string: 325\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# print maximum word index\n",
        "\n",
        "max_word_index = max([index for word, index in tokenizer.word_index.items()])\n",
        "print(f\"Maximum word index: {max_word_index}\")\n",
        "\n",
        "# print max length each string\n",
        "\n",
        "max_length = data_text['Modified_Commentary'].str.len().max()\n",
        "\n",
        "print(f\"Maximum length of a string: {max_length}\")\n",
        "\n",
        "max_text_index = data_text[data_text['Modified_Commentary'].str.len() == max_length].index[0]\n",
        "\n",
        "print(f\"Index of maximum length of a string: {max_text_index}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGttxktsG13r"
      },
      "outputs": [],
      "source": [
        "def rnn_model():\n",
        "\n",
        "  model_rnn = Sequential()\n",
        "  model_rnn.add(Embedding(input_dim=3583, output_dim= 100, input_length=max_len))\n",
        "  model_rnn.add(SimpleRNN(100, return_sequences=True)) # Pass return_sequences to LSTM\n",
        "  model_rnn.add(SimpleRNN(100))\n",
        "  model_rnn.add(Dense(3583, activation='softmax'))\n",
        "  model_rnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model_rnn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97facD44HLCf",
        "outputId": "bde6b18b-180d-4110-d09b-33bfeca1652e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = rnn_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "RzfIzQFjHPW-",
        "outputId": "d75fb95c-9fb9-4a15-9db0-556b82974066"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSBzKE0aHRgY",
        "outputId": "5c484845-d13b-4f31-8166-3c15844da319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 134ms/step - accuracy: 0.0669 - loss: 6.3407\n",
            "Epoch 2/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 143ms/step - accuracy: 0.1078 - loss: 5.5329\n",
            "Epoch 3/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 143ms/step - accuracy: 0.1653 - loss: 4.9323\n",
            "Epoch 4/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 142ms/step - accuracy: 0.1993 - loss: 4.5457\n",
            "Epoch 5/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 149ms/step - accuracy: 0.2276 - loss: 4.2437\n",
            "Epoch 6/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 131ms/step - accuracy: 0.2467 - loss: 4.0219\n",
            "Epoch 7/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 128ms/step - accuracy: 0.2692 - loss: 3.7896\n",
            "Epoch 8/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 129ms/step - accuracy: 0.2880 - loss: 3.6104\n",
            "Epoch 9/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 127ms/step - accuracy: 0.3179 - loss: 3.4011\n",
            "Epoch 10/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 127ms/step - accuracy: 0.3333 - loss: 3.2322\n",
            "Epoch 11/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 125ms/step - accuracy: 0.3572 - loss: 3.0762\n",
            "Epoch 12/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 127ms/step - accuracy: 0.3805 - loss: 2.9335\n",
            "Epoch 13/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 129ms/step - accuracy: 0.3989 - loss: 2.8074\n",
            "Epoch 14/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 128ms/step - accuracy: 0.4241 - loss: 2.6711\n",
            "Epoch 15/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 128ms/step - accuracy: 0.4388 - loss: 2.5740\n",
            "Epoch 16/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 128ms/step - accuracy: 0.4683 - loss: 2.4444\n",
            "Epoch 17/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 124ms/step - accuracy: 0.4823 - loss: 2.3353\n",
            "Epoch 18/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 121ms/step - accuracy: 0.4971 - loss: 2.2655\n",
            "Epoch 19/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 123ms/step - accuracy: 0.5203 - loss: 2.1483\n",
            "Epoch 20/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 129ms/step - accuracy: 0.5363 - loss: 2.0668\n",
            "Epoch 21/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 129ms/step - accuracy: 0.5545 - loss: 1.9714\n",
            "Epoch 22/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 124ms/step - accuracy: 0.5654 - loss: 1.9132\n",
            "Epoch 23/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 138ms/step - accuracy: 0.5823 - loss: 1.8341\n",
            "Epoch 24/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 133ms/step - accuracy: 0.5941 - loss: 1.7853\n",
            "Epoch 25/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 129ms/step - accuracy: 0.6027 - loss: 1.7264\n",
            "Epoch 26/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 128ms/step - accuracy: 0.6180 - loss: 1.6640\n",
            "Epoch 27/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 128ms/step - accuracy: 0.6312 - loss: 1.5961\n",
            "Epoch 28/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 127ms/step - accuracy: 0.6379 - loss: 1.5637\n",
            "Epoch 29/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 128ms/step - accuracy: 0.6504 - loss: 1.5081\n",
            "Epoch 30/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 128ms/step - accuracy: 0.6617 - loss: 1.4558\n",
            "Epoch 31/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 128ms/step - accuracy: 0.6692 - loss: 1.4203\n",
            "Epoch 32/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 128ms/step - accuracy: 0.6765 - loss: 1.3762\n",
            "Epoch 33/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 128ms/step - accuracy: 0.6893 - loss: 1.3328\n",
            "Epoch 34/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 129ms/step - accuracy: 0.6888 - loss: 1.3181\n",
            "Epoch 35/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 132ms/step - accuracy: 0.6973 - loss: 1.2825\n",
            "Epoch 36/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 130ms/step - accuracy: 0.7060 - loss: 1.2415\n",
            "Epoch 37/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 130ms/step - accuracy: 0.7086 - loss: 1.2232\n",
            "Epoch 38/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 131ms/step - accuracy: 0.7162 - loss: 1.1923\n",
            "Epoch 39/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 129ms/step - accuracy: 0.7204 - loss: 1.1731\n",
            "Epoch 40/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 131ms/step - accuracy: 0.7254 - loss: 1.1591\n",
            "Epoch 41/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 131ms/step - accuracy: 0.7340 - loss: 1.1212\n",
            "Epoch 42/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 131ms/step - accuracy: 0.7285 - loss: 1.1224\n",
            "Epoch 43/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 129ms/step - accuracy: 0.7422 - loss: 1.0707\n",
            "Epoch 44/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 123ms/step - accuracy: 0.7440 - loss: 1.0605\n",
            "Epoch 45/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 121ms/step - accuracy: 0.7521 - loss: 1.0392\n",
            "Epoch 46/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 120ms/step - accuracy: 0.7513 - loss: 1.0287\n",
            "Epoch 47/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 120ms/step - accuracy: 0.7489 - loss: 1.0231\n",
            "Epoch 48/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 119ms/step - accuracy: 0.7591 - loss: 1.0004\n",
            "Epoch 49/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 121ms/step - accuracy: 0.7652 - loss: 0.9694\n",
            "Epoch 50/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 134ms/step - accuracy: 0.7705 - loss: 0.9454\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ae17cc5c460>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x,y,epochs= 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgddyA7Y7nai"
      },
      "source": [
        "## With accuracy of 50 percent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0w4viYqHZg4",
        "outputId": "321f8b38-1de4-48b0-e491-563586c96498"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence 1:\n",
            "First 10 words: out caught by uthappa umesh yadav strikes and removes the\n",
            "Actual next 10 words: big fish he bowled much better compared to his first\n",
            "Predicted next 10 words: big fish he bowled a little shimmy down the track\n",
            "\n",
            "Sentence 2:\n",
            "First 10 words: four that's harsh on the bowler that didn't deserve to\n",
            "Actual next 10 words: go to the boundary it was banged in short and\n",
            "Predicted next 10 words: go to the boundary mohit moves across and swishes it\n",
            "\n",
            "Sentence 3:\n",
            "First 10 words: four welcome to delhi says iyer shortish and wide outside\n",
            "Actual next 10 words: off iyer treks back and fiercely cuts it behind square\n",
            "Predicted next 10 words: off iyer treks back and fiercely cuts it behind square\n",
            "\n",
            "Sentence 4:\n",
            "First 10 words: out caught by billings zak attack strikes trap set and\n",
            "Actual next 10 words: trap sprung so batsman's promotion fails lasted for just two\n",
            "Predicted next 10 words: trap sprung so batsman's promotion fails lasted for a strategic\n",
            "\n",
            "Sentence 5:\n",
            "First 10 words: four that's a gift and batsman accepts it gleefully half\n",
            "Actual next 10 words: volley on off stump batsman takes it from there and\n",
            "Predicted next 10 words: volley on off stump the dew causing the ball to\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "eval_data = data_text.iloc[-5:]\n",
        "eval_sequences = tokenizer.texts_to_sequences(eval_data['Modified_Commentary'])\n",
        "max_predict_len = 10\n",
        "\n",
        "# Function to predict the next n words\n",
        "def predict_next_n_words(model, tokenizer, seed_text, n_words):\n",
        "    result = []\n",
        "    for _ in range(n_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_len, padding='pre')\n",
        "        predicted_probs = model.predict(token_list, verbose=0)\n",
        "        predicted_index = np.argmax(predicted_probs, axis=1)[0]\n",
        "        predicted_word = tokenizer.index_word[predicted_index]\n",
        "        result.append(predicted_word)\n",
        "        seed_text += ' ' + predicted_word\n",
        "    return result\n",
        "\n",
        "# Evaluate the model\n",
        "reverse_word_index = dict((i, word) for word, i in tokenizer.word_index.items())\n",
        "for i, seq in enumerate(eval_sequences):\n",
        "    if len(seq) > 10:\n",
        "        first_10_words = seq[:10]\n",
        "    else:\n",
        "        first_10_words = seq\n",
        "\n",
        "    first_10_words_text = ' '.join(reverse_word_index.get(word, '?') for word in first_10_words)\n",
        "    predicted_words = predict_next_n_words(model, tokenizer, first_10_words_text, max_predict_len)\n",
        "    actual_next_10_words = seq[10:20] if len(seq) > 20 else seq[10:]\n",
        "    actual_next_10_words_text = ' '.join(reverse_word_index.get(word, '?') for word in actual_next_10_words)\n",
        "\n",
        "    print(f\"Sentence {i+1}:\")\n",
        "    print(f\"First 10 words: {first_10_words_text}\")\n",
        "    print(f\"Actual next 10 words: {actual_next_10_words_text}\")\n",
        "    print(f\"Predicted next 10 words: {' '.join(predicted_words)}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSOC5cSPSWGr",
        "outputId": "678e2e91-2cca-408a-e555-5f7cb40d8747"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence 1:\n",
            "First 10 words: four exquisite he's seeing the cricket ball like a football\n",
            "Actual next 10 words: all timing he is not trying to hit the leather\n",
            "Predicted next 10 words: all the power to go past it past the diving\n",
            "\n",
            "Sentence 2:\n",
            "First 10 words: four starts with a full toss on leg easy peasy\n",
            "Actual next 10 words: for batsman he clips it in front of square on\n",
            "Predicted next 10 words: for batsman he clips it in front of square on\n",
            "\n",
            "Sentence 3:\n",
            "First 10 words: 2 runs to long on 50 run stand in the\n",
            "Actual next 10 words: fifth over a gentle nudge into the leg side followed\n",
            "Predicted next 10 words: fifth over a gentle nudge into the leg side followed\n",
            "\n",
            "Sentence 4:\n",
            "First 10 words: out caught by uthappa the umpire took ages to raise\n",
            "Actual next 10 words: his finger perhaps it looked like he had a look\n",
            "Predicted next 10 words: his finger perhaps it looked like he gets a faint\n",
            "\n",
            "Sentence 5:\n",
            "First 10 words: four cheeky delicate and effective uses the slightest of width\n",
            "Actual next 10 words: on this short ball outside off and sends it wide\n",
            "Predicted next 10 words: on this delivery batsman swivels across one more off the\n",
            "\n",
            "Sentence 6:\n",
            "First 10 words: out caught by uthappa umesh yadav strikes and removes the\n",
            "Actual next 10 words: big fish he bowled much better compared to his first\n",
            "Predicted next 10 words: big fish he bowled a little shimmy down the track\n",
            "\n",
            "Sentence 7:\n",
            "First 10 words: four that's harsh on the bowler that didn't deserve to\n",
            "Actual next 10 words: go to the boundary it was banged in short and\n",
            "Predicted next 10 words: go to the boundary mohit moves across and swishes it\n",
            "\n",
            "Sentence 8:\n",
            "First 10 words: four welcome to delhi says iyer shortish and wide outside\n",
            "Actual next 10 words: off iyer treks back and fiercely cuts it behind square\n",
            "Predicted next 10 words: off iyer treks back and fiercely cuts it behind square\n",
            "\n",
            "Sentence 9:\n",
            "First 10 words: out caught by billings zak attack strikes trap set and\n",
            "Actual next 10 words: trap sprung so batsman's promotion fails lasted for just two\n",
            "Predicted next 10 words: trap sprung so batsman's promotion fails lasted for a strategic\n",
            "\n",
            "Sentence 10:\n",
            "First 10 words: four that's a gift and batsman accepts it gleefully half\n",
            "Actual next 10 words: volley on off stump batsman takes it from there and\n",
            "Predicted next 10 words: volley on off stump the dew causing the ball to\n",
            "\n"
          ]
        }
      ],
      "source": [
        "eval_data_1 = data_text.iloc[-10:]\n",
        "\n",
        "eval_sequences = tokenizer.texts_to_sequences(eval_data_1['Modified_Commentary'])\n",
        "max_predict_len = 10\n",
        "\n",
        "# Function to predict the next n words\n",
        "def predict_next_n_words(model, tokenizer, seed_text, n_words):\n",
        "    result = []\n",
        "    for _ in range(n_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_len, padding='pre')\n",
        "        predicted_probs = model.predict(token_list, verbose=0)\n",
        "        predicted_index = np.argmax(predicted_probs, axis=1)[0]\n",
        "        predicted_word = tokenizer.index_word[predicted_index]\n",
        "        result.append(predicted_word)\n",
        "        seed_text += ' ' + predicted_word\n",
        "    return result\n",
        "\n",
        "# Evaluate the model\n",
        "reverse_word_index = dict((i, word) for word, i in tokenizer.word_index.items())\n",
        "for i, seq in enumerate(eval_sequences):\n",
        "    if len(seq) > 10:\n",
        "        first_10_words = seq[:10]\n",
        "    else:\n",
        "        first_10_words = seq\n",
        "\n",
        "    first_10_words_text = ' '.join(reverse_word_index.get(word, '?') for word in first_10_words)\n",
        "    predicted_words = predict_next_n_words(model, tokenizer, first_10_words_text, max_predict_len)\n",
        "    actual_next_10_words = seq[10:20] if len(seq) > 20 else seq[10:]\n",
        "    actual_next_10_words_text = ' '.join(reverse_word_index.get(word, '?') for word in actual_next_10_words)\n",
        "\n",
        "    print(f\"Sentence {i+1}:\")\n",
        "    print(f\"First 10 words: {first_10_words_text}\")\n",
        "    print(f\"Actual next 10 words: {actual_next_10_words_text}\")\n",
        "    print(f\"Predicted next 10 words: {' '.join(predicted_words)}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mvOA2vOZSq5a",
        "outputId": "cfb60052-b1cc-41d9-d2e4-b97adf6737a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 121ms/step - accuracy: 0.7960 - loss: 0.7946\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ae126332fe0>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x,y,epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbv87oCmDXCu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model, save_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4y4lN3cGCDvU"
      },
      "outputs": [],
      "source": [
        "save_model(model, 'model_rnn_1.keras')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq7_0BHz7uIf"
      },
      "source": [
        "## With model accuracy of 90 percent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "xufsVl9dTBYQ",
        "outputId": "b731cf78-87e8-4c66-d1e3-bfef5de700fb"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b363dce9a6cd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "model.fit(x,y,epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ssIxqaqHnRk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}