{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trdF3fXVa13z",
        "outputId": "a6a9eb53-db54-4cd6-d82a-b82f856541cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.16.2\n",
            "  Downloading tensorflow-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (590.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (0.5.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (0.2.0)\n",
            "Collecting h5py>=3.10.0 (from tensorflow==2.16.2)\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.2)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (1.64.1)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.2)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras>=3.0.0 (from tensorflow==2.16.2)\n",
            "  Downloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (0.37.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (1.25.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.16.2) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.2) (13.7.1)\n",
            "Collecting namex (from keras>=3.0.0->tensorflow==2.16.2)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Collecting optree (from keras>=3.0.0->tensorflow==2.16.2)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (2024.6.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.2) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2) (0.1.2)\n",
            "Installing collected packages: namex, optree, ml-dtypes, h5py, tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.11.0 keras-3.4.1 ml-dtypes-0.3.2 namex-0.0.8 optree-0.11.0 tensorboard-2.16.2 tensorflow-2.16.2\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.16.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CjLbfvNCoVqz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Eo2eKQthoVqz"
      },
      "outputs": [],
      "source": [
        "data_text  = pd.read_csv('/content/df_commentary_new.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "t_uzaPqaUivF"
      },
      "outputs": [],
      "source": [
        "def data_processing(data,number_of_rows, list_of_columns):\n",
        "    data = data.drop(columns= list_of_columns,axis=1)\n",
        "    data = data.head(number_of_rows)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1nmA3ZtbWZeA"
      },
      "outputs": [],
      "source": [
        "def tokenize(data):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(data['Modified_Commentary'])\n",
        "    return tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qIRqxVsofcGL"
      },
      "outputs": [],
      "source": [
        "def input_sequences(data):\n",
        "  input_sequences = []\n",
        "  for i in range(len(data_text['Modified_Commentary'])):\n",
        "      text = data_text['Modified_Commentary'][i]\n",
        "      token_list = tokenizer.texts_to_sequences([text])[0]\n",
        "      for i in range(1, len(token_list)):\n",
        "          n_gram_sequence = token_list[:i+1]\n",
        "          input_sequences.append(n_gram_sequence)\n",
        "\n",
        "  max_len = max(len(x) for x in input_sequences)\n",
        "\n",
        "  return input_sequences, max_len\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym9S8lJ0gIXo",
        "outputId": "f8f9f8ef-b91b-4bd2-fd7c-028230887ff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x shape :  {(45086, 153)}\n",
            "y shape :  {(45086, 3583)}\n"
          ]
        }
      ],
      "source": [
        "### Calling all the functions\n",
        "\n",
        "dropped_columns = ['Unnamed: 0']\n",
        "data_text =  data_processing(data_text, 1000, dropped_columns)\n",
        "tokenizer  = tokenize(data_text)\n",
        "input_sequences, max_len = input_sequences(data_text)\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen=max_len + 1, padding='pre')\n",
        "padded_input_sequences\n",
        "x = padded_input_sequences[:, :-1]\n",
        "y = padded_input_sequences[:, -1]\n",
        "y = to_categorical(y, num_classes=len(tokenizer.word_index)+1)\n",
        "print('x shape : ',{x.shape})\n",
        "print('y shape : ',{y.shape})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSYPEEdYhcO8",
        "outputId": "9effdaaa-8828-40e7-e55f-ef6d78a79522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum word index: 3582\n",
            "Maximum length of a string: 798\n",
            "Index of maximum length of a string: 325\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# print maximum word index\n",
        "\n",
        "max_word_index = max([index for word, index in tokenizer.word_index.items()])\n",
        "print(f\"Maximum word index: {max_word_index}\")\n",
        "\n",
        "# print max length each string\n",
        "\n",
        "max_length = data_text['Modified_Commentary'].str.len().max()\n",
        "\n",
        "print(f\"Maximum length of a string: {max_length}\")\n",
        "\n",
        "max_text_index = data_text[data_text['Modified_Commentary'].str.len() == max_length].index[0]\n",
        "\n",
        "print(f\"Index of maximum length of a string: {max_text_index}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7CPjkYlPhsf5"
      },
      "outputs": [],
      "source": [
        "def lstm_model():\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=3583, output_dim= 100, input_length=max_len))\n",
        "  model.add(LSTM(100, return_sequences=True)) # Pass return_sequences to LSTM\n",
        "  model.add(LSTM(100))\n",
        "  model.add(Dense(3583, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VDFvqbloVq2",
        "outputId": "4b55230a-1f38-4464-b31e-ab2961a770b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = lstm_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "zEnXTxyGoVq2",
        "outputId": "6fb146d6-9025-4ce4-fc14-b9bd641724c9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1saydO3joVq2",
        "outputId": "34dc409b-10e1-4374-8cf5-6fbaed776e24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 16ms/step - accuracy: 0.0674 - loss: 6.3617\n",
            "Epoch 2/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 16ms/step - accuracy: 0.0919 - loss: 5.6823\n",
            "Epoch 3/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.1337 - loss: 5.2318\n",
            "Epoch 4/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.1669 - loss: 4.8916\n",
            "Epoch 5/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.1943 - loss: 4.6226\n",
            "Epoch 6/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.2144 - loss: 4.4041\n",
            "Epoch 7/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.2257 - loss: 4.2211\n",
            "Epoch 8/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.2347 - loss: 4.0685\n",
            "Epoch 9/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.2426 - loss: 3.9285\n",
            "Epoch 10/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.2531 - loss: 3.7907\n",
            "Epoch 11/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.2625 - loss: 3.6956\n",
            "Epoch 12/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - accuracy: 0.2705 - loss: 3.5512\n",
            "Epoch 13/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.2848 - loss: 3.4506\n",
            "Epoch 14/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.2977 - loss: 3.3455\n",
            "Epoch 15/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.3074 - loss: 3.2629\n",
            "Epoch 16/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.3231 - loss: 3.1709\n",
            "Epoch 17/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.3327 - loss: 3.0911\n",
            "Epoch 18/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.3459 - loss: 3.0131\n",
            "Epoch 19/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.3559 - loss: 2.9372\n",
            "Epoch 20/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.3668 - loss: 2.8810\n",
            "Epoch 21/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.3750 - loss: 2.8272\n",
            "Epoch 22/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - accuracy: 0.3880 - loss: 2.7563\n",
            "Epoch 23/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.3944 - loss: 2.7039\n",
            "Epoch 24/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.4040 - loss: 2.6475\n",
            "Epoch 25/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.4161 - loss: 2.6049\n",
            "Epoch 26/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.4295 - loss: 2.5323\n",
            "Epoch 27/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.4381 - loss: 2.4839\n",
            "Epoch 28/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.4403 - loss: 2.4409\n",
            "Epoch 29/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.4558 - loss: 2.3849\n",
            "Epoch 30/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.4627 - loss: 2.3466\n",
            "Epoch 31/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.4676 - loss: 2.3044\n",
            "Epoch 32/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.4800 - loss: 2.2529\n",
            "Epoch 33/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.4882 - loss: 2.2176\n",
            "Epoch 34/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.4963 - loss: 2.1677\n",
            "Epoch 35/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.5067 - loss: 2.1144\n",
            "Epoch 36/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.5107 - loss: 2.0993\n",
            "Epoch 37/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - accuracy: 0.5192 - loss: 2.0556\n",
            "Epoch 38/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.5269 - loss: 2.0209\n",
            "Epoch 39/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.5385 - loss: 1.9734\n",
            "Epoch 40/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.5447 - loss: 1.9275\n",
            "Epoch 41/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - accuracy: 0.5567 - loss: 1.8910\n",
            "Epoch 42/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.5534 - loss: 1.8896\n",
            "Epoch 43/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - accuracy: 0.5727 - loss: 1.8170\n",
            "Epoch 44/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.5707 - loss: 1.8033\n",
            "Epoch 45/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.5817 - loss: 1.7706\n",
            "Epoch 46/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - accuracy: 0.5881 - loss: 1.7250\n",
            "Epoch 47/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - accuracy: 0.6001 - loss: 1.6949\n",
            "Epoch 48/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.6016 - loss: 1.6703\n",
            "Epoch 49/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.6130 - loss: 1.6289\n",
            "Epoch 50/50\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.6163 - loss: 1.6053\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d6a01affa90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model.fit(x,y,epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "b8ab0fJ75EjB"
      },
      "outputs": [],
      "source": [
        "eval_data = data_text.iloc[-5:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBbnAk5u55S9",
        "outputId": "982b0e4f-5c59-485d-bd8a-1d3084f35101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results on the last 5 sentences: [0.9745728373527527, 0.800000011920929]\n",
            "Accuracy on the last 5 sentences: 0.800000011920929\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "Predictions on the last 5 sentences: [[6.7445174e-11 2.8243122e-07 1.2627577e-05 ... 7.9858522e-26\n",
            "  3.3178926e-26 2.4318808e-18]\n",
            " [2.2047382e-10 9.9783674e-02 6.8807247e-04 ... 1.4604362e-19\n",
            "  2.0284194e-19 4.4226571e-19]\n",
            " [2.4552094e-12 6.0368648e-06 4.1524290e-06 ... 9.1795321e-30\n",
            "  2.6861045e-27 4.7719846e-32]\n",
            " [3.9265768e-11 3.0926611e-07 8.2775739e-07 ... 5.7052353e-24\n",
            "  1.4696759e-24 6.7838443e-18]\n",
            " [9.0894064e-10 4.5546920e-05 8.2390343e-06 ... 1.7422334e-22\n",
            "  5.8705002e-28 4.7136469e-27]]\n"
          ]
        }
      ],
      "source": [
        "eval_sequences = tokenizer.texts_to_sequences(eval_data['Modified_Commentary'])\n",
        "eval_padded = pad_sequences(eval_sequences, maxlen=max_len + 1, padding='pre')\n",
        "\n",
        "x_eval = eval_padded[:, :-1]\n",
        "y_eval = eval_padded[:, -1]\n",
        "y_eval = to_categorical(y_eval, num_classes=len(tokenizer.word_index)+1)\n",
        "\n",
        "# Evaluate the model\n",
        "results = model.evaluate(x_eval, y_eval, verbose=0)\n",
        "print(f\"Evaluation results on the last 5 sentences: {results}\")\n",
        "\n",
        "# Calculate accuracy on the last 5 sentences\n",
        "accuracy = results[1]  # The second element in results corresponds to accuracy\n",
        "print(f\"Accuracy on the last 5 sentences: {accuracy}\")\n",
        "\n",
        "# Make predictions on the last 5 sentences\n",
        "predictions = model.predict(x_eval)\n",
        "print(f\"Predictions on the last 5 sentences: {predictions}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INysXr9f90d0"
      },
      "source": [
        "### with 65 percent accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q84LUOjq7v1z",
        "outputId": "160793cf-378e-45fe-e3ce-142e5a3f6b90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results on the last 5 sentences: [0.9745728373527527, 0.800000011920929]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Original sentence 1: out caught by uthappa umesh yadav strikes and removes the big fish he bowled much better compared to his first spell and earns himself a wicket it was a pacy test match line and length short of a good length delivery on fourth fifth stump line batsman gets a faint outside tickle looking to run it down towards third man settles into the safe mitts of uthappa batsman c uthappa b bowler 39 25 4s 7\n",
            "Predicted next word for sentence 1: 7\n",
            "\n",
            "Original sentence 2: four that's harsh on the bowler that didn't deserve to go to the boundary it was banged in short and bowler bent his back there iyer is surprised by the pace and bounce on that delivery he jumps and just sticks his bat out hoping that it doesn't hit him the ball flies past the keeper off his shoulder and dribbles away into the third man fence the umpire thinks it came off the bat and gives four runs\n",
            "Predicted next word for sentence 2: a\n",
            "\n",
            "Original sentence 3: four welcome to delhi says iyer shortish and wide outside off iyer treks back and fiercely cuts it behind square on the off side gets it well out of the reach of backward point\n",
            "Predicted next word for sentence 3: point\n",
            "\n",
            "Original sentence 4: out caught by billings zak attack strikes trap set and trap sprung so batsman's promotion fails lasted for just two balls it was a fuller length delivery on off stump line batsman went for a half hearted flick it appeared that the ball might have stopped on the wicket nonetheless he was early into the shot and it was the slower ball from bowler that fooled the batsman there skies it towards deep square leg billings sprawls in forward and pouches it with ease bowler roars in delight batsman c billings b bowler 1 2\n",
            "Predicted next word for sentence 4: 2\n",
            "\n",
            "Original sentence 5: four that's a gift and batsman accepts it gleefully half volley on off stump batsman takes it from there and flicks it fiercely past mid on rockets away to the fence\n",
            "Predicted next word for sentence 5: fence\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Separate into x_eval and y_eval\n",
        "x_eval = eval_padded[:, :-1]\n",
        "y_eval = eval_padded[:, -1]\n",
        "y_eval = to_categorical(y_eval, num_classes=len(tokenizer.word_index)+1)\n",
        "\n",
        "# Evaluate the model\n",
        "results = model.evaluate(x_eval, y_eval, verbose=0)\n",
        "print(f\"Evaluation results on the last 5 sentences: {results}\")\n",
        "\n",
        "# Make predictions on the last 5 sentences\n",
        "predictions = model.predict(x_eval)\n",
        "predicted_indices = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Function to convert sequences back to words\n",
        "def sequences_to_texts(tokenizer, sequences):\n",
        "    reverse_word_index = dict((i, word) for word, i in tokenizer.word_index.items())\n",
        "    texts = []\n",
        "    for sequence in sequences:\n",
        "        words = [reverse_word_index.get(i, '?') for i in sequence]\n",
        "        texts.append(' '.join(words))\n",
        "    return texts\n",
        "\n",
        "# Convert original and predicted sequences to texts\n",
        "original_texts = sequences_to_texts(tokenizer, eval_sequences)\n",
        "predicted_texts = sequences_to_texts(tokenizer, predicted_indices.reshape(-1, 1))\n",
        "\n",
        "# Print each of the words from the original and predicted sequences\n",
        "for i in range(len(original_texts)):\n",
        "    print(f\"Original sentence {i+1}: {original_texts[i]}\")\n",
        "    print(f\"Predicted next word for sentence {i+1}: {predicted_texts[i]}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi1fU58y9Q3e",
        "outputId": "6254d432-8564-427b-f9a7-88d80c2fc0a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1:\n",
            "First 10 words: out caught by uthappa umesh yadav strikes and removes the\n",
            "Actual next 10 words: big fish he bowled much better compared to his first\n",
            "Predicted next 10 words: big fish he is in some form alright comes up\n",
            "\n",
            "Sentence 2:\n",
            "First 10 words: four that's harsh on the bowler that didn't deserve to\n",
            "Actual next 10 words: go to the boundary it was banged in short and\n",
            "Predicted next 10 words: fetch it from batsman who waits with the ball flying\n",
            "\n",
            "Sentence 3:\n",
            "First 10 words: four welcome to delhi says iyer shortish and wide outside\n",
            "Actual next 10 words: off iyer treks back and fiercely cuts it behind square\n",
            "Predicted next 10 words: off batsman gets inside the line and helps it on\n",
            "\n",
            "Sentence 4:\n",
            "First 10 words: out caught by billings zak attack strikes trap set and\n",
            "Actual next 10 words: trap sprung so batsman's promotion fails lasted for just two\n",
            "Predicted next 10 words: trap sprung the finger bowler gets a pie out of\n",
            "\n",
            "Sentence 5:\n",
            "First 10 words: four that's a gift and batsman accepts it gleefully half\n",
            "Actual next 10 words: volley on off stump batsman takes it from there and\n",
            "Predicted next 10 words: volley on the pads batsman gets a feather of the\n",
            "\n"
          ]
        }
      ],
      "source": [
        "eval_sequences = tokenizer.texts_to_sequences(eval_data['Modified_Commentary'])\n",
        "max_predict_len = 10\n",
        "\n",
        "# Function to predict the next n words\n",
        "def predict_next_n_words(model, tokenizer, seed_text, n_words):\n",
        "    result = []\n",
        "    for _ in range(n_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_len, padding='pre')\n",
        "        predicted_probs = model.predict(token_list, verbose=0)\n",
        "        predicted_index = np.argmax(predicted_probs, axis=1)[0]\n",
        "        predicted_word = tokenizer.index_word[predicted_index]\n",
        "        result.append(predicted_word)\n",
        "        seed_text += ' ' + predicted_word\n",
        "    return result\n",
        "\n",
        "# Evaluate the model\n",
        "reverse_word_index = dict((i, word) for word, i in tokenizer.word_index.items())\n",
        "for i, seq in enumerate(eval_sequences):\n",
        "    if len(seq) > 10:\n",
        "        first_10_words = seq[:10]\n",
        "    else:\n",
        "        first_10_words = seq\n",
        "\n",
        "    first_10_words_text = ' '.join(reverse_word_index.get(word, '?') for word in first_10_words)\n",
        "    predicted_words = predict_next_n_words(model, tokenizer, first_10_words_text, max_predict_len)\n",
        "    actual_next_10_words = seq[10:20] if len(seq) > 20 else seq[10:]\n",
        "    actual_next_10_words_text = ' '.join(reverse_word_index.get(word, '?') for word in actual_next_10_words)\n",
        "\n",
        "    print(f\"Sentence {i+1}:\")\n",
        "    print(f\"First 10 words: {first_10_words_text}\")\n",
        "    print(f\"Actual next 10 words: {actual_next_10_words_text}\")\n",
        "    print(f\"Predicted next 10 words: {' '.join(predicted_words)}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edMBY9RM-JUf"
      },
      "source": [
        "## with the accuracy of 90 percent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVinX9b50O0o",
        "outputId": "9b2fedff-3a3e-4412-a06b-b81a95b604d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - accuracy: 0.8590 - loss: 0.6160\n",
            "Epoch 2/15\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8628 - loss: 0.6055\n",
            "Epoch 3/15\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8657 - loss: 0.5946\n",
            "Epoch 4/15\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8654 - loss: 0.5887\n",
            "Epoch 5/15\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - accuracy: 0.8686 - loss: 0.5806\n",
            "Epoch 6/15\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8734 - loss: 0.5673\n",
            "Epoch 7/15\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - accuracy: 0.8728 - loss: 0.5694\n",
            "Epoch 8/15\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8746 - loss: 0.5541\n",
            "Epoch 9/15\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8776 - loss: 0.5539\n",
            "Epoch 10/15\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - accuracy: 0.8797 - loss: 0.5446\n",
            "Epoch 11/15\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8812 - loss: 0.5358\n",
            "Epoch 12/15\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8832 - loss: 0.5199\n",
            "Epoch 13/15\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8845 - loss: 0.5191\n",
            "Epoch 14/15\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8880 - loss: 0.5099\n",
            "Epoch 15/15\n",
            "\u001b[1m1409/1409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8870 - loss: 0.5087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d6a025eacb0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "model.fit(x,y,epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ghaCbYqAWY6V"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model, save_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "RnBrtrZrWSyX"
      },
      "outputs": [],
      "source": [
        "save_model(model, 'model_lstm_5.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0qFqnADDgy8",
        "outputId": "0fb343ea-9cf7-472f-b6ef-bc3e5d7d5984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results on the last 5 sentences: [0.178151935338974, 1.0]\n",
            "Accuracy on the last 5 sentences: 1.0\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Predictions on the last 5 sentences: [[2.6682059e-11 9.3183551e-11 8.3306261e-08 ... 3.5693134e-28\n",
            "  1.8218195e-33 9.3182855e-22]\n",
            " [1.5750453e-11 9.6197281e-04 4.3774176e-07 ... 5.8988461e-26\n",
            "  4.5774917e-27 3.0567537e-21]\n",
            " [1.7673569e-13 4.0504697e-09 8.6667762e-07 ... 1.9472560e-34\n",
            "  8.1974051e-35 2.3082990e-34]\n",
            " [4.1753745e-12 1.5166934e-10 3.2718833e-10 ... 9.8802642e-28\n",
            "  1.1610399e-34 2.7810996e-21]\n",
            " [1.9452910e-10 3.5226595e-08 8.7374674e-10 ... 1.6121795e-26\n",
            "  0.0000000e+00 3.8950349e-31]]\n"
          ]
        }
      ],
      "source": [
        "eval_sequences = tokenizer.texts_to_sequences(eval_data['Modified_Commentary'])\n",
        "eval_padded = pad_sequences(eval_sequences, maxlen=max_len + 1, padding='pre')\n",
        "\n",
        "x_eval = eval_padded[:, :-1]\n",
        "y_eval = eval_padded[:, -1]\n",
        "y_eval = to_categorical(y_eval, num_classes=len(tokenizer.word_index)+1)\n",
        "\n",
        "# Evaluate the model\n",
        "results = model.evaluate(x_eval, y_eval, verbose=0)\n",
        "print(f\"Evaluation results on the last 5 sentences: {results}\")\n",
        "\n",
        "# Calculate accuracy on the last 5 sentences\n",
        "accuracy = results[1]  # The second element in results corresponds to accuracy\n",
        "print(f\"Accuracy on the last 5 sentences: {accuracy}\")\n",
        "\n",
        "# Make predictions on the last 5 sentences\n",
        "predictions = model.predict(x_eval)\n",
        "print(f\"Predictions on the last 5 sentences: {predictions}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS97OpTDDgpe",
        "outputId": "aa7f927f-ef42-4d2d-8d38-ad96e9e26cf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1:\n",
            "First 10 words: out caught by uthappa umesh yadav strikes and removes the\n",
            "Actual next 10 words: big fish he bowled much better compared to his first\n",
            "Predicted next 10 words: big fish he bowled much better compared to his first\n",
            "\n",
            "Sentence 2:\n",
            "First 10 words: four that's harsh on the bowler that didn't deserve to\n",
            "Actual next 10 words: go to the boundary it was banged in short and\n",
            "Predicted next 10 words: go to the boundary it was banged in short and\n",
            "\n",
            "Sentence 3:\n",
            "First 10 words: four welcome to delhi says iyer shortish and wide outside\n",
            "Actual next 10 words: off iyer treks back and fiercely cuts it behind square\n",
            "Predicted next 10 words: off iyer treks back and fiercely cuts it behind square\n",
            "\n",
            "Sentence 4:\n",
            "First 10 words: out caught by billings zak attack strikes trap set and\n",
            "Actual next 10 words: trap sprung so batsman's promotion fails lasted for just two\n",
            "Predicted next 10 words: trap sprung so batsman's promotion fails lasted for the bowling\n",
            "\n",
            "Sentence 5:\n",
            "First 10 words: four that's a gift and batsman accepts it gleefully half\n",
            "Actual next 10 words: volley on off stump batsman takes it from there and\n",
            "Predicted next 10 words: volley on off stump batsman takes it on and splices\n",
            "\n"
          ]
        }
      ],
      "source": [
        "eval_sequences = tokenizer.texts_to_sequences(eval_data['Modified_Commentary'])\n",
        "max_predict_len = 10\n",
        "\n",
        "# Function to predict the next n words\n",
        "def predict_next_n_words(model, tokenizer, seed_text, n_words):\n",
        "    result = []\n",
        "    for _ in range(n_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_len, padding='pre')\n",
        "        predicted_probs = model.predict(token_list, verbose=0)\n",
        "        predicted_index = np.argmax(predicted_probs, axis=1)[0]\n",
        "        predicted_word = tokenizer.index_word[predicted_index]\n",
        "        result.append(predicted_word)\n",
        "        seed_text += ' ' + predicted_word\n",
        "    return result\n",
        "\n",
        "# Evaluate the model\n",
        "reverse_word_index = dict((i, word) for word, i in tokenizer.word_index.items())\n",
        "for i, seq in enumerate(eval_sequences):\n",
        "    if len(seq) > 10:\n",
        "        first_10_words = seq[:10]\n",
        "    else:\n",
        "        first_10_words = seq\n",
        "\n",
        "    first_10_words_text = ' '.join(reverse_word_index.get(word, '?') for word in first_10_words)\n",
        "    predicted_words = predict_next_n_words(model, tokenizer, first_10_words_text, max_predict_len)\n",
        "    actual_next_10_words = seq[10:20] if len(seq) > 20 else seq[10:]\n",
        "    actual_next_10_words_text = ' '.join(reverse_word_index.get(word, '?') for word in actual_next_10_words)\n",
        "\n",
        "    print(f\"Sentence {i+1}:\")\n",
        "    print(f\"First 10 words: {first_10_words_text}\")\n",
        "    print(f\"Actual next 10 words: {actual_next_10_words_text}\")\n",
        "    print(f\"Predicted next 10 words: {' '.join(predicted_words)}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "hbPtcxMlEH4A"
      },
      "outputs": [],
      "source": [
        "eval_data_1 = data_text.iloc[-10:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVJqO5PWELjA",
        "outputId": "cf30cac2-b7e3-4129-d47c-e93e83b9ec1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1:\n",
            "First 10 words: four exquisite he's seeing the cricket ball like a football\n",
            "Actual next 10 words: all timing he is not trying to hit the leather\n",
            "Predicted next 10 words: all timing he was scarced for runs wanted to throw\n",
            "\n",
            "Sentence 2:\n",
            "First 10 words: four starts with a full toss on leg easy peasy\n",
            "Actual next 10 words: for batsman he clips it in front of square on\n",
            "Predicted next 10 words: for batsman he clips it in front of square on\n",
            "\n",
            "Sentence 3:\n",
            "First 10 words: 2 runs to long on 50 run stand in the\n",
            "Actual next 10 words: fifth over a gentle nudge into the leg side followed\n",
            "Predicted next 10 words: fifth full one in this man didn't deserve the pace\n",
            "\n",
            "Sentence 4:\n",
            "First 10 words: out caught by uthappa the umpire took ages to raise\n",
            "Actual next 10 words: his finger perhaps it looked like he had a look\n",
            "Predicted next 10 words: his finger perhaps it looked like he had to turn\n",
            "\n",
            "Sentence 5:\n",
            "First 10 words: four cheeky delicate and effective uses the slightest of width\n",
            "Actual next 10 words: on this short ball outside off and sends it wide\n",
            "Predicted next 10 words: on this short ball outside off and sends it wide\n",
            "\n",
            "Sentence 6:\n",
            "First 10 words: out caught by uthappa umesh yadav strikes and removes the\n",
            "Actual next 10 words: big fish he bowled much better compared to his first\n",
            "Predicted next 10 words: big fish he bowled much better compared to his first\n",
            "\n",
            "Sentence 7:\n",
            "First 10 words: four that's harsh on the bowler that didn't deserve to\n",
            "Actual next 10 words: go to the boundary it was banged in short and\n",
            "Predicted next 10 words: go to the boundary it was banged in short and\n",
            "\n",
            "Sentence 8:\n",
            "First 10 words: four welcome to delhi says iyer shortish and wide outside\n",
            "Actual next 10 words: off iyer treks back and fiercely cuts it behind square\n",
            "Predicted next 10 words: off iyer treks back and fiercely cuts it behind square\n",
            "\n",
            "Sentence 9:\n",
            "First 10 words: out caught by billings zak attack strikes trap set and\n",
            "Actual next 10 words: trap sprung so batsman's promotion fails lasted for just two\n",
            "Predicted next 10 words: trap sprung so batsman's promotion fails lasted for the bowling\n",
            "\n",
            "Sentence 10:\n",
            "First 10 words: four that's a gift and batsman accepts it gleefully half\n",
            "Actual next 10 words: volley on off stump batsman takes it from there and\n",
            "Predicted next 10 words: volley on off stump batsman takes it on and splices\n",
            "\n"
          ]
        }
      ],
      "source": [
        "eval_sequences = tokenizer.texts_to_sequences(eval_data_1['Modified_Commentary'])\n",
        "max_predict_len = 10\n",
        "\n",
        "# Function to predict the next n words\n",
        "def predict_next_n_words(model, tokenizer, seed_text, n_words):\n",
        "    result = []\n",
        "    for _ in range(n_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_len, padding='pre')\n",
        "        predicted_probs = model.predict(token_list, verbose=0)\n",
        "        predicted_index = np.argmax(predicted_probs, axis=1)[0]\n",
        "        predicted_word = tokenizer.index_word[predicted_index]\n",
        "        result.append(predicted_word)\n",
        "        seed_text += ' ' + predicted_word\n",
        "    return result\n",
        "\n",
        "# Evaluate the model\n",
        "reverse_word_index = dict((i, word) for word, i in tokenizer.word_index.items())\n",
        "for i, seq in enumerate(eval_sequences):\n",
        "    if len(seq) > 10:\n",
        "        first_10_words = seq[:10]\n",
        "    else:\n",
        "        first_10_words = seq\n",
        "\n",
        "    first_10_words_text = ' '.join(reverse_word_index.get(word, '?') for word in first_10_words)\n",
        "    predicted_words = predict_next_n_words(model, tokenizer, first_10_words_text, max_predict_len)\n",
        "    actual_next_10_words = seq[10:20] if len(seq) > 20 else seq[10:]\n",
        "    actual_next_10_words_text = ' '.join(reverse_word_index.get(word, '?') for word in actual_next_10_words)\n",
        "\n",
        "    print(f\"Sentence {i+1}:\")\n",
        "    print(f\"First 10 words: {first_10_words_text}\")\n",
        "    print(f\"Actual next 10 words: {actual_next_10_words_text}\")\n",
        "    print(f\"Predicted next 10 words: {' '.join(predicted_words)}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuJZP_l-Eci1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}